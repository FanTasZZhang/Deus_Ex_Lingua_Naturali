{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just plain boring</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entirely predictable and lacks energy</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no surprises and very few laughs</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very powerful</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the most fun film of the summer</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  review sentiment\n",
       "0                      just plain boring  negative\n",
       "1  entirely predictable and lacks energy  negative\n",
       "2       no surprises and very few laughs  negative\n",
       "3                          very powerful  positive\n",
       "4        the most fun film of the summer  positive"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('./test_Dataset.csv')\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    3\n",
       "positive    3\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5,), (5,), (1,), (1,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews=imdb_data.review[:5]\n",
    "train_sentiments=imdb_data.sentiment[:5]\n",
    "\n",
    "test_reviews=imdb_data.review[5:]\n",
    "test_sentiments=imdb_data.sentiment[5:]\n",
    "\n",
    "train_reviews.shape,train_sentiments.shape, test_reviews.shape,test_sentiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    3\n",
       "positive    2\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentiments.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method that take in the training dataset, then return the positive and negative words log probability.\n",
    "Input: train_reviews: reviews (sentences) for training\n",
    "       train_sentiments: sentiments (label) for training\n",
    "       tfidf: boolean variable indicating whether using bow or tfidf\n",
    "       alpha: laplance smoothing variable, default to be 1.0\n",
    "       ngram_range: the scale of ngram model will be used, default = (1,1) unigram\n",
    "return: negative_word_log_prob_dict: dictionary that contains the word:log probability pair for negative class\n",
    "        positive_word_log_prob_dict: dictionary that contains the word:log probability pair for positive class\n",
    "        mnb: the trained multinomial naive bayes model, later can be used for testing\n",
    "        transformed_test_reviews: transformed test reviews that later can be used for testing\n",
    "'''\n",
    "\n",
    "def generate_log_prob(train_reviews, train_sentiments, tfidf=False, alpha=1.0, ngram_range = (1,1)):\n",
    "\n",
    "    if (tfidf):\n",
    "        #Tfidf vectorizer\n",
    "        vec=TfidfVectorizer(use_idf=tfidf, ngram_range=ngram_range)\n",
    "        #transformed train reviews\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        #transformed test reviews\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "    else:\n",
    "        vec=CountVectorizer(ngram_range=(1,1))\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "\n",
    "    #training the model\n",
    "    mnb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    #fitting the naive bayes for bag of words\n",
    "    mnb = mnb.fit(transformed_train_reviews, train_sentiments)\n",
    "    negative_log_prob = mnb.feature_log_prob_[0]\n",
    "    positive_log_prob = mnb.feature_log_prob_[1]\n",
    "\n",
    "    # Generate two dict: word:log_prob\n",
    "    negative_word_log_prob_dict = {}\n",
    "    positive_word_log_prob_dict = {}\n",
    "    for word, index in vec.vocabulary_.items():\n",
    "        negative_word_log_prob_dict[word] =   negative_log_prob[index]\n",
    "        positive_word_log_prob_dict[word] = positive_log_prob[index]\n",
    "    \n",
    "    return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_test_reviews, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 3 count wrong by value\n",
    "\n",
    "def func(positive_prob_dict, negative_prob_dict, dataset, threshold=0.1):\n",
    "    wrongly_classified_token_dict = {}\n",
    "    reweight_dict = {}\n",
    "    for sentence in dataset:\n",
    "        real_label = sentence[6:14]\n",
    "        tokens = sentence[17:].split(\" \")\n",
    "        for token in tokens:\n",
    "            if token not in wrongly_classified_token_dict:\n",
    "                wrongly_classified_token_dict[token] = 0\n",
    "        if real_label == \"positive\": # marked as negative\n",
    "            for token in tokens:\n",
    "                wrongly_classified_token_dict[token] += positive_prob_dict[token] - negative_prob_dict[token]\n",
    "        elif real_label == \"negative\": # marked as positive\n",
    "            for token in tokens:\n",
    "                wrongly_classified_token_dict[token] += negative_prob_dict[token] - positive_prob_dict[token]\n",
    "    \n",
    "    for word, prob in wrongly_classified_token_dict:\n",
    "        if wrongly_classified_token_dict[word] >= threshold * len(dataset):\n",
    "            reweight_dict[word] = 2\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos, mnb, transformed_test_reviews, vec= generate_log_prob(train_reviews, train_sentiments, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -2.833213344056216,\n",
       " 'plain': -2.833213344056216,\n",
       " 'boring': -2.833213344056216,\n",
       " 'entirely': -2.833213344056216,\n",
       " 'predictable': -2.833213344056216,\n",
       " 'and': -2.4277482359480516,\n",
       " 'lacks': -2.833213344056216,\n",
       " 'energy': -2.833213344056216,\n",
       " 'no': -2.833213344056216,\n",
       " 'surprises': -2.833213344056216,\n",
       " 'very': -2.833213344056216,\n",
       " 'few': -2.833213344056216,\n",
       " 'laughs': -2.833213344056216,\n",
       " 'powerful': -3.5263605246161616,\n",
       " 'the': -3.5263605246161616,\n",
       " 'most': -3.5263605246161616,\n",
       " 'fun': -3.5263605246161616,\n",
       " 'film': -3.5263605246161616,\n",
       " 'of': -3.5263605246161616,\n",
       " 'summer': -3.5263605246161616}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -3.367295829986474,\n",
       " 'plain': -3.367295829986474,\n",
       " 'boring': -3.367295829986474,\n",
       " 'entirely': -3.367295829986474,\n",
       " 'predictable': -3.367295829986474,\n",
       " 'and': -3.367295829986474,\n",
       " 'lacks': -3.367295829986474,\n",
       " 'energy': -3.367295829986474,\n",
       " 'no': -3.367295829986474,\n",
       " 'surprises': -3.367295829986474,\n",
       " 'very': -2.6741486494265287,\n",
       " 'few': -3.367295829986474,\n",
       " 'laughs': -3.367295829986474,\n",
       " 'powerful': -2.6741486494265287,\n",
       " 'the': -2.2686835413183646,\n",
       " 'most': -2.6741486494265287,\n",
       " 'fun': -2.6741486494265287,\n",
       " 'film': -2.6741486494265287,\n",
       " 'of': -2.6741486494265287,\n",
       " 'summer': -2.6741486494265287}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65054103, 0.34945897]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_bow_predict = mnb.predict(transformed_test_reviews)\n",
    "math.e ** mnb.predict_log_proba(transformed_test_reviews[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65054103, 0.34945897]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(transformed_test_reviews[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(transformed_test_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['negative', 'positive'], dtype='<U8'), array([0.6, 0.4]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.classes_, math.e ** mnb.class_log_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method will take in a word:scale dict, then take in the negative and positive word:log_probability dict, manually change the weight of the words in the model and the dict\n",
    "\n",
    "'''\n",
    "\n",
    "def change_weight(negative_word_change_scale, positive_word_change_scale, model, negative_word_log_prob_dict, positive_word_log_prob_dict, vec):\n",
    "    for word, scale in negative_word_change_scale.items():\n",
    "        # change the weight of words in negative and positive word:log_prob dict\n",
    "        negative_word_log_prob_dict[word] += np.log(scale)\n",
    "\n",
    "        # change the weight of words in the model\n",
    "        index_in_model = vec.vocabulary_[word]\n",
    "        model.feature_log_prob_[0][index_in_model] += np.log(scale)\n",
    "\n",
    "    for word, scale in positive_word_change_scale.items():\n",
    "        # change the weight of words in negative and positive word:log_prob dict\n",
    "        positive_word_log_prob_dict[word] += np.log(scale)\n",
    "\n",
    "        # change the weight of words in the model\n",
    "        index_in_model = vec.vocabulary_[word]\n",
    "        model.feature_log_prob_[1][index_in_model] += np.log(scale)\n",
    "\n",
    "    return negative_word_log_prob_dict, positive_word_log_prob_dict, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_prob = {}\n",
    "for word, prob in neg.items():\n",
    "    neg_prob[word] = math.e ** neg[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prob = {}\n",
    "for word, prob in pos.items():\n",
    "    pos_prob[word] = math.e ** pos[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.833213344056216"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = vec.vocabulary_[\"just\"]\n",
    "mnb.feature_log_prob_[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -2.833213344056216,\n",
       " 'plain': -2.833213344056216,\n",
       " 'boring': -2.833213344056216,\n",
       " 'entirely': -2.833213344056216,\n",
       " 'predictable': -2.833213344056216,\n",
       " 'and': -2.4277482359480516,\n",
       " 'lacks': -2.833213344056216,\n",
       " 'energy': -2.833213344056216,\n",
       " 'no': -2.833213344056216,\n",
       " 'surprises': -2.833213344056216,\n",
       " 'very': -2.833213344056216,\n",
       " 'few': -2.833213344056216,\n",
       " 'laughs': -2.833213344056216,\n",
       " 'powerful': -3.5263605246161616,\n",
       " 'the': -3.5263605246161616,\n",
       " 'most': -3.5263605246161616,\n",
       " 'fun': -3.5263605246161616,\n",
       " 'film': -3.5263605246161616,\n",
       " 'of': -3.5263605246161616,\n",
       " 'summer': -3.5263605246161616}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_word_change_scale = {}\n",
    "positive_word_change_scale = {}\n",
    "negative_word_change_scale[\"just\"] = 0.5\n",
    "positive_word_change_scale[\"just\"] = 2\n",
    "\n",
    "neg, pos, model = change_weight(negative_word_change_scale, positive_word_change_scale, mnb, neg, pos, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.367295829986474"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = vec.vocabulary_[\"just\"]\n",
    "mnb.feature_log_prob_[1][index] - np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -2.6741486494265287,\n",
       " 'plain': -3.367295829986474,\n",
       " 'boring': -3.367295829986474,\n",
       " 'entirely': -3.367295829986474,\n",
       " 'predictable': -3.367295829986474,\n",
       " 'and': -3.367295829986474,\n",
       " 'lacks': -3.367295829986474,\n",
       " 'energy': -3.367295829986474,\n",
       " 'no': -3.367295829986474,\n",
       " 'surprises': -3.367295829986474,\n",
       " 'very': -2.6741486494265287,\n",
       " 'few': -3.367295829986474,\n",
       " 'laughs': -3.367295829986474,\n",
       " 'powerful': -2.6741486494265287,\n",
       " 'the': -2.2686835413183646,\n",
       " 'most': -2.6741486494265287,\n",
       " 'fun': -2.6741486494265287,\n",
       " 'film': -2.6741486494265287,\n",
       " 'of': -2.6741486494265287,\n",
       " 'summer': -2.6741486494265287}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word, prob in neg.items():\n",
    "#     neg[word] = math.e ** neg[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word, prob in pos.items():\n",
    "#     pos[word] = math.e ** pos[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': 0.05882352941176471,\n",
       " 'plain': 0.05882352941176471,\n",
       " 'boring': 0.05882352941176471,\n",
       " 'entirely': 0.05882352941176471,\n",
       " 'predictable': 0.05882352941176471,\n",
       " 'and': 0.08823529411764708,\n",
       " 'lacks': 0.05882352941176471,\n",
       " 'energy': 0.05882352941176471,\n",
       " 'no': 0.05882352941176471,\n",
       " 'surprises': 0.05882352941176471,\n",
       " 'very': 0.05882352941176471,\n",
       " 'few': 0.05882352941176471,\n",
       " 'laughs': 0.05882352941176471,\n",
       " 'powerful': 0.029411764705882353,\n",
       " 'the': 0.029411764705882353,\n",
       " 'most': 0.029411764705882353,\n",
       " 'fun': 0.029411764705882353,\n",
       " 'film': 0.029411764705882353,\n",
       " 'of': 0.029411764705882353,\n",
       " 'summer': 0.029411764705882353}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -3.5263605246161616,\n",
       " 'plain': -2.833213344056216,\n",
       " 'boring': -2.833213344056216,\n",
       " 'entirely': -2.833213344056216,\n",
       " 'predictable': -2.833213344056216,\n",
       " 'and': -2.4277482359480516,\n",
       " 'lacks': -2.833213344056216,\n",
       " 'energy': -2.833213344056216,\n",
       " 'no': -2.833213344056216,\n",
       " 'surprises': -2.833213344056216,\n",
       " 'very': -2.833213344056216,\n",
       " 'few': -2.833213344056216,\n",
       " 'laughs': -2.833213344056216,\n",
       " 'powerful': -3.5263605246161616,\n",
       " 'the': -3.5263605246161616,\n",
       " 'most': -3.5263605246161616,\n",
       " 'fun': -3.5263605246161616,\n",
       " 'film': -3.5263605246161616,\n",
       " 'of': -3.5263605246161616,\n",
       " 'summer': -3.5263605246161616}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': 0.034482758620689655,\n",
       " 'plain': 0.034482758620689655,\n",
       " 'boring': 0.034482758620689655,\n",
       " 'entirely': 0.034482758620689655,\n",
       " 'predictable': 0.034482758620689655,\n",
       " 'and': 0.034482758620689655,\n",
       " 'lacks': 0.034482758620689655,\n",
       " 'energy': 0.034482758620689655,\n",
       " 'no': 0.034482758620689655,\n",
       " 'surprises': 0.034482758620689655,\n",
       " 'very': 0.06896551724137932,\n",
       " 'few': 0.034482758620689655,\n",
       " 'laughs': 0.034482758620689655,\n",
       " 'powerful': 0.06896551724137932,\n",
       " 'the': 0.10344827586206895,\n",
       " 'most': 0.06896551724137932,\n",
       " 'fun': 0.06896551724137932,\n",
       " 'film': 0.06896551724137932,\n",
       " 'of': 0.06896551724137932,\n",
       " 'summer': 0.06896551724137932}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'just': -2.6741486494265287,\n",
       " 'plain': -3.367295829986474,\n",
       " 'boring': -3.367295829986474,\n",
       " 'entirely': -3.367295829986474,\n",
       " 'predictable': -3.367295829986474,\n",
       " 'and': -3.367295829986474,\n",
       " 'lacks': -3.367295829986474,\n",
       " 'energy': -3.367295829986474,\n",
       " 'no': -3.367295829986474,\n",
       " 'surprises': -3.367295829986474,\n",
       " 'very': -2.6741486494265287,\n",
       " 'few': -3.367295829986474,\n",
       " 'laughs': -3.367295829986474,\n",
       " 'powerful': -2.6741486494265287,\n",
       " 'the': -2.2686835413183646,\n",
       " 'most': -2.6741486494265287,\n",
       " 'fun': -2.6741486494265287,\n",
       " 'film': -2.6741486494265287,\n",
       " 'of': -2.6741486494265287,\n",
       " 'summer': -2.6741486494265287}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3277c0aca1018dde18e8f269bdb355d963b34ecf48e4cbbed77653a47ee184b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
