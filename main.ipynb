{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import string \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews=imdb_data.review[:30000]\n",
    "train_sentiments=imdb_data.sentiment[:30000]\n",
    "\n",
    "val_reviews=imdb_data.review[30000:40000]\n",
    "val_sentiments=imdb_data.sentiment[30000:40000]\n",
    "\n",
    "test_reviews=imdb_data.review[40000:]\n",
    "test_sentiments=imdb_data.sentiment[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    container = []\n",
    "    for review in reviews:\n",
    "        review = review.replace(\"<br />\", \"\")\n",
    "        for ele in string.punctuation:\n",
    "                if ele in review:\n",
    "                        review = review.replace(ele, \"\")\n",
    "        container.append(review)\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = preprocess(train_reviews)\n",
    "val_reviews = preprocess(val_reviews)\n",
    "test_reviews = preprocess(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method that take in the training dataset, then return the positive and negative words log probability.\n",
    "Input: train_reviews: reviews (sentences) for training\n",
    "       train_sentiments: sentiments (label) for training\n",
    "       val_reviews: reviews (sentences) for validation\n",
    "       test_reviews: reviews (sentences) for testing\n",
    "       tfidf: boolean variable indicating whether using bow or tfidf\n",
    "       alpha: laplance smoothing variable, default to be 1.0\n",
    "       ngram_range: the scale of ngram model will be used, default = (1,1) unigram\n",
    "return: negative_word_log_prob_dict: dictionary that contains the word:log probability pair for negative class\n",
    "        positive_word_log_prob_dict: dictionary that contains the word:log probability pair for positive class\n",
    "        mnb: the trained multinomial naive bayes model, later can be used for testing\n",
    "        transformed_val_reviews: transformed val reviews that later can be used for validation\n",
    "        transformed_test_reviews: transformed test reviews that later can be used for testing\n",
    "        vec: either the tfidfVectorize build from tfidf model or the CountVectorizer build from Bag of word model.\n",
    "'''\n",
    "\n",
    "def generate_log_prob(train_reviews, train_sentiments, val_reviews, test_reviews, tfidf=False, alpha=1.0, ngram_range = (1,1)):\n",
    "\n",
    "    if (tfidf):\n",
    "        #Tfidf vectorizer\n",
    "        vec=TfidfVectorizer(use_idf=tfidf, ngram_range=ngram_range)\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "    else:\n",
    "        vec=CountVectorizer(ngram_range=(1,1))\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "\n",
    "    #training the model\n",
    "    mnb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    #fitting the naive bayes for bag of words\n",
    "    mnb = mnb.fit(transformed_train_reviews, train_sentiments)\n",
    "    negative_log_prob = mnb.feature_log_prob_[0]\n",
    "    positive_log_prob = mnb.feature_log_prob_[1]\n",
    "\n",
    "    # Generate two dict: word:log_prob\n",
    "    negative_word_log_prob_dict = {}\n",
    "    positive_word_log_prob_dict = {}\n",
    "    for word, index in vec.vocabulary_.items():\n",
    "        negative_word_log_prob_dict[word] = negative_log_prob[index]\n",
    "        positive_word_log_prob_dict[word] = positive_log_prob[index]\n",
    "    \n",
    "    return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_val_reviews, transformed_test_reviews, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reweight_dict(positive_prob_dict, negative_prob_dict, dataset, threshold=0.1):\n",
    "    wrongly_classified_token_dict = {} # counts how many times a token has negative impact on wrongly classified sentence\n",
    "    token_dict = {} # counts how many times a token has appeared in total\n",
    "    reweight_dict = {}\n",
    "    for sentence in dataset:\n",
    "        real_label = sentence[6:14]\n",
    "        tokens = sentence[17:].split(\" \")\n",
    "        for token in tokens:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = 1\n",
    "            else:\n",
    "                token_dict[token] += 1\n",
    "        if real_label == \"positive\": # marked as negative\n",
    "            for token in tokens:\n",
    "                if token not in positive_prob_dict: continue\n",
    "                elif positive_prob_dict[token] < negative_prob_dict[token]:\n",
    "                    if token not in wrongly_classified_token_dict:\n",
    "                        wrongly_classified_token_dict[token] = 1\n",
    "                    else:\n",
    "                        wrongly_classified_token_dict[token] += 1\n",
    "        elif real_label == \"negative\": # marked as positive\n",
    "            for token in tokens:\n",
    "                if token not in positive_prob_dict: continue\n",
    "                elif negative_prob_dict[token] < positive_prob_dict[token]:\n",
    "                    if token not in wrongly_classified_token_dict:\n",
    "                        wrongly_classified_token_dict[token] = 1\n",
    "                    else:\n",
    "                        wrongly_classified_token_dict[token] += 1\n",
    "    # print(wrongly_classified_token_dict)\n",
    "    for word, prob in wrongly_classified_token_dict.items():\n",
    "        # print(word, prob)\n",
    "        weight = 0\n",
    "        if positive_prob_dict[word] < negative_prob_dict[word]:\n",
    "            weight = positive_prob_dict[word] - negative_prob_dict[word]\n",
    "        elif negative_prob_dict[word] < positive_prob_dict[word]:\n",
    "            weight = negative_prob_dict[word] - positive_prob_dict[word]\n",
    "        multiplier = 1 - wrongly_classified_token_dict[word] / token_dict[word]\n",
    "        if multiplier == 0:\n",
    "            reweight_dict[word] = 0\n",
    "        else:\n",
    "            reweight_dict[word] = np.exp(weight * multiplier)\n",
    "    return reweight_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method will take in a word:scale dict, then take in the negative and positive word:log_probability dict, manually change the weight of the words in the model and the dict\n",
    "Input: word_change_scale: this is the word-scale dictionary, how much the weight of the word should be changed, For example if the value is 0.5, we will say \n",
    "                          the probability of the word in negative class should multiply 0.5, in original probability, we take power to the scale\n",
    "       model: the trained naive bayes model, which the feature_log_prob_ attribute will be manually changed based on previous two params\n",
    "       negative_word_log_prob_dict: dictionary that contains the word:log probability pair for negative class, which some values will be changed\n",
    "       positive_word_log_prob_dict: dictionary that contains the word:log probability pair for positive class, which some values will be changed\n",
    "       vec: either the tfidfVectorize build from tfidf model or the CountVectorizer build from Bag of word model.\n",
    "return: negative_word_change_scale: The modified negative dict\n",
    "        positive_word_change_scale: The modified positive dict\n",
    "        model: The modified naive bayes model\n",
    "'''\n",
    "\n",
    "def change_weight(word_change_scale, model, negative_word_log_prob_dict, positive_word_log_prob_dict, vec):\n",
    "    for word, scale in word_change_scale.items():\n",
    "        # change the weight of words in negative and positive word:log_prob dict\n",
    "        negative_word_log_prob_dict[word] *= scale\n",
    "        positive_word_log_prob_dict[word] *= scale\n",
    "\n",
    "        # change the weight of words in the model\n",
    "        index_in_model = vec.vocabulary_[word]\n",
    "        model.feature_log_prob_[0][index_in_model] *= scale\n",
    "        model.feature_log_prob_[1][index_in_model] *= scale\n",
    "\n",
    "    return negative_word_log_prob_dict, positive_word_log_prob_dict, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Word - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos, mnb, transformed_val_reviews, transformed_test_reviews, vec= generate_log_prob(train_reviews, train_sentiments, val_reviews, test_reviews, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy is 0.8411, test accuracy is 0.8419\n"
     ]
    }
   ],
   "source": [
    "val_pred = mnb.predict(transformed_val_reviews)\n",
    "test_pred = mnb.predict(transformed_test_reviews)\n",
    "val_acc = accuracy_score(val_sentiments, val_pred)\n",
    "test_acc = accuracy_score(test_sentiments, test_pred)\n",
    "print(f\"val accuracy is {val_acc}, test accuracy is {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.83      0.86      0.85      5022\n",
      "    Negative       0.86      0.82      0.84      4978\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(val_sentiments,val_pred,target_names=['Positive','Negative'])\n",
    "print(mnb_bow_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight the model using perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_inference(reweight, pos, neg, test_reviews, test_sentiments, test_start=40000):\n",
    "    correct = 0\n",
    "    for i in range(len(test_reviews)):\n",
    "        word_list = test_reviews[i].strip().split()\n",
    "        final_result = 0\n",
    "        \n",
    "        for word in word_list:\n",
    "            weight = 1\n",
    "            pprob = 0\n",
    "            nprob = 0\n",
    "            if word in reweight:\n",
    "                weight = reweight[word]\n",
    "            if word in pos:\n",
    "                pprob = pos[word]\n",
    "            if word in neg:\n",
    "                nprob = neg[word]\n",
    "            final_result += weight*pprob - weight*nprob\n",
    "        if (final_result > 0 and test_sentiments[i+test_start] == \"positive\") or (final_result < 0 and test_sentiments[i+test_start] == \"negative\"):\n",
    "            correct += 1\n",
    "    print(correct/len(test_reviews))\n",
    "    return correct/len(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(positive_prob_dict, negative_prob_dict, val_reviews, val_sentiments, test_reviews, test_sentiments, max_iter=10, learning_rate=0.01, val_start=30000):\n",
    "    \"\"\"\n",
    "    need to handle unseen word here\n",
    "    has to be a method\n",
    "    \"\"\"\n",
    "    initial_weight = {}\n",
    "    for word in positive_prob_dict.keys():\n",
    "        initial_weight[word] = 1\n",
    "    for word in negative_prob_dict.keys():\n",
    "        initial_weight[word] = 1\n",
    "    for i in range(max_iter):\n",
    "        random_array = np.arange(len(val_sentiments))\n",
    "        np.random.shuffle(random_array)\n",
    "        correct = 0\n",
    "        for index in random_array:\n",
    "            word_list = val_reviews[index].strip().split()\n",
    "            final_result = 0\n",
    "            for word in word_list:\n",
    "                weight = 1\n",
    "                pprob = 0\n",
    "                nprob = 0\n",
    "                if word in initial_weight:\n",
    "                    weight = initial_weight[word]\n",
    "                if word in positive_prob_dict:\n",
    "                    pprob = positive_prob_dict[word]\n",
    "                if word in negative_prob_dict:\n",
    "                    nprob = negative_prob_dict[word]\n",
    "                final_result += weight*pprob - weight*nprob\n",
    "            if (final_result > 0 and val_sentiments[index+val_start] == \"positive\") or (final_result < 0 and val_sentiments[index+val_start] == \"negative\"):\n",
    "                correct += 1\n",
    "                for word in word_list:\n",
    "                    if word in positive_prob_dict and word in negative_prob_dict:\n",
    "                        initial_weight[word] -= learning_rate/len(val_sentiments)*initial_weight[word]\n",
    "                continue\n",
    "            else:\n",
    "                for word in word_list:\n",
    "                    if word in positive_prob_dict and word in negative_prob_dict:\n",
    "                        if val_sentiments[index+val_start] == \"positive\":\n",
    "                            initial_weight[word] += learning_rate*((positive_prob_dict[word]-negative_prob_dict[word]) - 1/len(val_sentiments)*initial_weight[word])\n",
    "                        else:\n",
    "                            initial_weight[word] += learning_rate*((negative_prob_dict[word]-positive_prob_dict[word]) - 1/len(val_sentiments)*initial_weight[word])\n",
    "        test_acc = naive_inference(initial_weight, positive_prob_dict, negative_prob_dict, test_reviews, test_sentiments)\n",
    "        print(f\"finish training epoch {i}, the val accuracy is {correct/len(val_sentiments)}, the test accuracy is {test_acc}\")\n",
    "        \n",
    "    return initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8542\n",
      "finish training epoch 0, the val accuracy is 0.846, the test accuracy is 0.8542\n",
      "0.8573\n",
      "finish training epoch 1, the val accuracy is 0.859, the test accuracy is 0.8573\n"
     ]
    }
   ],
   "source": [
    "reweight = perceptron_update(pos, neg, val_reviews, val_sentiments, test_reviews, test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos, mnb = change_weight(reweight, mnb, neg, pos, vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = mnb.predict(transformed_val_reviews)\n",
    "test_pred = mnb.predict(transformed_test_reviews)\n",
    "val_acc = accuracy_score(val_sentiments, val_pred)\n",
    "test_acc = accuracy_score(test_sentiments, test_pred)\n",
    "print(f\"val accuracy is {val_acc}, test accuracy is {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60d1cc28a4b92593bd5dc5bc27ccc3190a35517554a34efe05fccaa5f4e07df9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
