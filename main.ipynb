{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import string \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews=imdb_data.review[:30000]\n",
    "train_sentiments=imdb_data.sentiment[:30000]\n",
    "\n",
    "val_reviews=imdb_data.review[30000:40000]\n",
    "val_sentiments=imdb_data.sentiment[30000:40000]\n",
    "\n",
    "test_reviews=imdb_data.review[40000:]\n",
    "test_sentiments=imdb_data.sentiment[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    container = []\n",
    "    for review in reviews:\n",
    "        review = review.replace(\"<br />\", \"\")\n",
    "        for ele in string.punctuation:\n",
    "                if ele in review:\n",
    "                        review = review.replace(ele, \"\")\n",
    "        container.append(review)\n",
    "    return container\n",
    "\n",
    "def preprocess_sentiment(sentiments):\n",
    "    container = []\n",
    "    for sentiment in sentiments:\n",
    "        container.append(sentiment)\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = preprocess(train_reviews)\n",
    "val_reviews = preprocess(val_reviews)\n",
    "test_reviews = preprocess(test_reviews)\n",
    "train_sentiments = preprocess_sentiment(train_sentiments)\n",
    "val_sentiments = preprocess_sentiment(val_sentiments)\n",
    "test_sentiments = preprocess_sentiment(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method that take in the training dataset, then return the positive and negative words log probability.\n",
    "Input: train_reviews: reviews (sentences) for training\n",
    "       train_sentiments: sentiments (label) for training\n",
    "       val_reviews: reviews (sentences) for validation\n",
    "       test_reviews: reviews (sentences) for testing\n",
    "       tfidf: boolean variable indicating whether using bow or tfidf\n",
    "       alpha: laplance smoothing variable, default to be 1.0\n",
    "       ngram_range: the scale of ngram model will be used, default = (1,1) unigram\n",
    "return: negative_word_log_prob_dict: dictionary that contains the word:log probability pair for negative class\n",
    "        positive_word_log_prob_dict: dictionary that contains the word:log probability pair for positive class\n",
    "        mnb: the trained multinomial naive bayes model, later can be used for testing\n",
    "        transformed_val_reviews: transformed val reviews that later can be used for validation\n",
    "        transformed_test_reviews: transformed test reviews that later can be used for testing\n",
    "        vec: either the tfidfVectorize build from tfidf model or the CountVectorizer build from Bag of word model.\n",
    "'''\n",
    "\n",
    "def generate_log_prob(train_reviews, train_sentiments,  test_reviews, val_reviews=None, tfidf=False, alpha=1.0, ngram_range = (1,1)):\n",
    "\n",
    "    if (tfidf):\n",
    "        #Tfidf vectorizer\n",
    "        vec=TfidfVectorizer(use_idf=tfidf, ngram_range=ngram_range)\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        if val_reviews is not None:\n",
    "            transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "    else:\n",
    "        vec=CountVectorizer(ngram_range=(1,1))\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        if val_reviews is not None:\n",
    "            transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "\n",
    "    #training the model\n",
    "    mnb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    #fitting the naive bayes for bag of words\n",
    "    mnb = mnb.fit(transformed_train_reviews, train_sentiments)\n",
    "    \n",
    "    negative_log_prob = mnb.feature_log_prob_[0]\n",
    "    positive_log_prob = mnb.feature_log_prob_[1]\n",
    "\n",
    "    # Generate two dict: word:log_prob\n",
    "    negative_word_log_prob_dict = {}\n",
    "    positive_word_log_prob_dict = {}\n",
    "    for word, index in vec.vocabulary_.items():\n",
    "        negative_word_log_prob_dict[word] = negative_log_prob[index]\n",
    "        positive_word_log_prob_dict[word] = positive_log_prob[index]\n",
    "    if val_reviews is None:\n",
    "        return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_test_reviews, vec\n",
    "    else:\n",
    "        return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_val_reviews, transformed_test_reviews, vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Word - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos, mnb, transformed_val_reviews, transformed_test_reviews, vec= generate_log_prob(train_reviews, train_sentiments, test_reviews, val_reviews=val_reviews, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.032443811652895 -15.049387153559886\n"
     ]
    }
   ],
   "source": [
    "unseen_neg = mnb.feature_log_prob_[0].min()\n",
    "unseen_pos = mnb.feature_log_prob_[1].min()\n",
    "print(unseen_neg, unseen_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy is 0.8449, test accuracy is 0.8489\n"
     ]
    }
   ],
   "source": [
    "val_pred = mnb.predict(transformed_val_reviews)\n",
    "test_pred = mnb.predict(transformed_test_reviews)\n",
    "val_acc = accuracy_score(val_sentiments, val_pred)\n",
    "test_acc = accuracy_score(test_sentiments, test_pred)\n",
    "print(f\"val accuracy is {val_acc}, test accuracy is {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_inference(reweight, pos, neg, unseen_neg, unseen_pos, test_reviews, test_sentiments):\n",
    "    correct = 0\n",
    "    for i in range(len(test_reviews)):\n",
    "        word_list = test_reviews[i].strip().split()\n",
    "        final_result = 0\n",
    "        \n",
    "        for word in word_list:\n",
    "            weight = 1\n",
    "            pprob = unseen_pos\n",
    "            nprob = unseen_neg\n",
    "            if word in reweight:\n",
    "                weight = reweight[word]\n",
    "            if word in pos:\n",
    "                pprob = pos[word]\n",
    "            if word in neg:\n",
    "                nprob = neg[word]\n",
    "            final_result += weight*pprob - weight*nprob\n",
    "        if (final_result > 0 and test_sentiments[i] == \"positive\") or (final_result < 0 and test_sentiments[i] == \"negative\"):\n",
    "            correct += 1\n",
    "    print(correct/len(test_reviews))\n",
    "    return correct/len(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8287\n"
     ]
    }
   ],
   "source": [
    "val_pred = naive_inference({}, pos, neg, unseen_neg, unseen_pos, val_reviews, val_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight the model using perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(positive_prob_dict, negative_prob_dict, unseen_pos, unseen_neg, val_reviews, val_sentiments, test_reviews, test_sentiments, max_iter=10, learning_rate=0.02):\n",
    "    \"\"\"\n",
    "    need to handle unseen word here\n",
    "    has to be a method\n",
    "    \"\"\"\n",
    "    initial_weight = {}\n",
    "    for i in range(max_iter):\n",
    "        random_array = np.arange(len(val_sentiments))\n",
    "        np.random.shuffle(random_array)\n",
    "        correct = 0\n",
    "        for index in random_array:\n",
    "            word_list = val_reviews[index].strip().split()\n",
    "            final_result = 0\n",
    "            for word in word_list:\n",
    "                weight = 1\n",
    "                pprob = unseen_pos\n",
    "                nprob = unseen_neg\n",
    "                if word not in initial_weight:\n",
    "                    initial_weight[word] = 1\n",
    "                if word in initial_weight:\n",
    "                    weight = initial_weight[word]\n",
    "                if word in positive_prob_dict:\n",
    "                    pprob = positive_prob_dict[word]\n",
    "                if word in negative_prob_dict:\n",
    "                    nprob = negative_prob_dict[word]\n",
    "                final_result += weight*pprob - weight*nprob\n",
    "            if (final_result > 0 and val_sentiments[index] == \"positive\") or (final_result < 0 and val_sentiments[index] == \"negative\"):\n",
    "                correct += 1\n",
    "                for word in word_list:\n",
    "                    initial_weight[word] -= learning_rate/len(val_sentiments)*initial_weight[word]\n",
    "            else:\n",
    "                for word in word_list:\n",
    "                    pprob = unseen_pos\n",
    "                    nprob = unseen_neg\n",
    "                    if word in positive_prob_dict:\n",
    "                        pprob = positive_prob_dict[word]\n",
    "                    if word in negative_prob_dict:\n",
    "                        nprob = negative_prob_dict[word]\n",
    "                    if val_sentiments[index] == \"positive\":\n",
    "                        initial_weight[word] += learning_rate*((pprob-nprob) - 1/len(val_sentiments)*initial_weight[word])\n",
    "                    else:\n",
    "                        initial_weight[word] += learning_rate*((nprob-pprob) - 1/len(val_sentiments)*initial_weight[word])\n",
    "        test_acc = naive_inference(initial_weight, positive_prob_dict, negative_prob_dict, unseen_neg, unseen_pos, test_reviews, test_sentiments)\n",
    "        print(f\"finish training epoch {i}, the val accuracy is {correct/len(val_sentiments)}, the test accuracy is {test_acc}\")\n",
    "        \n",
    "    return initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8689\n",
      "finish training epoch 0, the val accuracy is 0.8582, the test accuracy is 0.8689\n",
      "0.8746\n",
      "finish training epoch 1, the val accuracy is 0.8773, the test accuracy is 0.8746\n",
      "0.8768\n",
      "finish training epoch 2, the val accuracy is 0.887, the test accuracy is 0.8768\n",
      "0.8755\n",
      "finish training epoch 3, the val accuracy is 0.8927, the test accuracy is 0.8755\n",
      "0.8765\n",
      "finish training epoch 4, the val accuracy is 0.8965, the test accuracy is 0.8765\n",
      "0.8742\n",
      "finish training epoch 5, the val accuracy is 0.9032, the test accuracy is 0.8742\n",
      "0.8725\n",
      "finish training epoch 6, the val accuracy is 0.9055, the test accuracy is 0.8725\n",
      "0.8746\n",
      "finish training epoch 7, the val accuracy is 0.9112, the test accuracy is 0.8746\n",
      "0.8694\n",
      "finish training epoch 8, the val accuracy is 0.9189, the test accuracy is 0.8694\n",
      "0.8733\n",
      "finish training epoch 9, the val accuracy is 0.9212, the test accuracy is 0.8733\n"
     ]
    }
   ],
   "source": [
    "reweight = perceptron_update(pos, neg, unseen_pos, unseen_neg, val_reviews, val_sentiments, test_reviews, test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_printed_version = dict(sorted(reweight.items(), key=lambda item: item[1]))\n",
    "with open(\"weight_dict.txt\", \"w\") as f:\n",
    "    for k, v in weight_printed_version.items():\n",
    "        f.write(str(k))\n",
    "        f.write(\": \")\n",
    "        f.write(str(v))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('weight.pickle', 'wb') as handle:\n",
    "    pickle.dump(reweight, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60d1cc28a4b92593bd5dc5bc27ccc3190a35517554a34efe05fccaa5f4e07df9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
