{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\16514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import string \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews=imdb_data.review[:30000]\n",
    "train_sentiments=imdb_data.sentiment[:30000]\n",
    "\n",
    "val_reviews=imdb_data.review[30000:40000]\n",
    "val_sentiments=imdb_data.sentiment[30000:40000]\n",
    "\n",
    "test_reviews=imdb_data.review[40000:]\n",
    "test_sentiments=imdb_data.sentiment[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    container = []\n",
    "    for review in reviews:\n",
    "        review = review.replace(\"<br />\", \"\")\n",
    "        for ele in string.punctuation:\n",
    "                if ele in review:\n",
    "                        review = review.replace(ele, \"\")\n",
    "        container.append(review)\n",
    "    return container\n",
    "\n",
    "def preprocess_sentiment(sentiments):\n",
    "    container = []\n",
    "    for sentiment in sentiments:\n",
    "        container.append(sentiment)\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = preprocess(train_reviews)\n",
    "val_reviews = preprocess(val_reviews)\n",
    "test_reviews = preprocess(test_reviews)\n",
    "train_sentiments = preprocess_sentiment(train_sentiments)\n",
    "val_sentiments = preprocess_sentiment(val_sentiments)\n",
    "test_sentiments = preprocess_sentiment(test_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method that take in the training dataset, then return the positive and negative words log probability.\n",
    "Input: train_reviews: reviews (sentences) for training\n",
    "       train_sentiments: sentiments (label) for training\n",
    "       val_reviews: reviews (sentences) for validation\n",
    "       test_reviews: reviews (sentences) for testing\n",
    "       tfidf: boolean variable indicating whether using bow or tfidf\n",
    "       alpha: laplance smoothing variable, default to be 1.0\n",
    "       ngram_range: the scale of ngram model will be used, default = (1,1) unigram\n",
    "return: negative_word_log_prob_dict: dictionary that contains the word:log probability pair for negative class\n",
    "        positive_word_log_prob_dict: dictionary that contains the word:log probability pair for positive class\n",
    "        mnb: the trained multinomial naive bayes model, later can be used for testing\n",
    "        transformed_val_reviews: transformed val reviews that later can be used for validation\n",
    "        transformed_test_reviews: transformed test reviews that later can be used for testing\n",
    "        vec: either the tfidfVectorize build from tfidf model or the CountVectorizer build from Bag of word model.\n",
    "'''\n",
    "\n",
    "def generate_log_prob(train_reviews, train_sentiments,  test_reviews, val_reviews=None, tfidf=False, alpha=1.0, ngram_range = (1,1)):\n",
    "\n",
    "    if (tfidf):\n",
    "        #Tfidf vectorizer\n",
    "        vec=TfidfVectorizer(use_idf=tfidf, ngram_range=ngram_range)\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        if val_reviews is not None:\n",
    "            transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "    else:\n",
    "        vec=CountVectorizer(ngram_range=(1,1))\n",
    "        transformed_train_reviews=vec.fit_transform(train_reviews)\n",
    "        if val_reviews is not None:\n",
    "            transformed_val_reviews = vec.transform(val_reviews)\n",
    "        transformed_test_reviews=vec.transform(test_reviews)\n",
    "\n",
    "    #training the model\n",
    "    mnb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    #fitting the naive bayes for bag of words\n",
    "    mnb = mnb.fit(transformed_train_reviews, train_sentiments)\n",
    "    \n",
    "    negative_log_prob = mnb.feature_log_prob_[0]\n",
    "    positive_log_prob = mnb.feature_log_prob_[1]\n",
    "\n",
    "    # Generate two dict: word:log_prob\n",
    "    negative_word_log_prob_dict = {}\n",
    "    positive_word_log_prob_dict = {}\n",
    "    for word, index in vec.vocabulary_.items():\n",
    "        negative_word_log_prob_dict[word] = negative_log_prob[index]\n",
    "        positive_word_log_prob_dict[word] = positive_log_prob[index]\n",
    "    if val_reviews is None:\n",
    "        return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_test_reviews, vec\n",
    "    else:\n",
    "        return negative_word_log_prob_dict, positive_word_log_prob_dict, mnb, transformed_val_reviews, transformed_test_reviews, vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_inference(reweight, pos, neg, unseen_pos, unseen_neg, test_reviews, test_sentiments):\n",
    "    correct = 0\n",
    "    prediction = []\n",
    "    pattern = r'[^A-Za-z0-9]+'\n",
    "    for i in range(len(test_reviews)):\n",
    "        word_list = test_reviews[i]\n",
    "        word_list = re.sub(pattern, \" \", word_list.lower()).split()\n",
    "        # word_list = test_reviews[i].strip().lower().split()\n",
    "        final_result = 0\n",
    "        \n",
    "        for word in word_list:\n",
    "            weight = 1\n",
    "            pprob = unseen_pos\n",
    "            nprob = unseen_neg\n",
    "            if word in reweight:\n",
    "                weight = reweight[word]\n",
    "            if word in pos:\n",
    "                pprob = pos[word]\n",
    "            if word in neg:\n",
    "                nprob = neg[word]\n",
    "            final_result += weight*pprob - weight*nprob\n",
    "        if final_result > 0:\n",
    "            prediction.append(\"positive\")\n",
    "        elif final_result < 0:\n",
    "            prediction.append(\"negative\")\n",
    "        if (final_result > 0 and test_sentiments[i] == \"positive\") or (final_result < 0 and test_sentiments[i] == \"negative\"):\n",
    "            correct += 1\n",
    "    return prediction, correct/len(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reweight by Count Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reweight by Value Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reweight_dict(pos, neg, dataset, threshold=0.1):\n",
    "    wrongly_classified_dict = {} # counts how many times a token has negative impact on wrongly classified sentence\n",
    "    token_dict = {} # counts how many times a token has appeared in total\n",
    "    reweight_dict = {}\n",
    "    for label, sentence in dataset:\n",
    "        real_label = label\n",
    "        tokens = sentence\n",
    "        for token in tokens:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = 1\n",
    "            else:\n",
    "                token_dict[token] += 1\n",
    "        if real_label == \"positive\": # marked as negative\n",
    "            for token in tokens:\n",
    "                if token not in pos: continue\n",
    "                elif pos[token] < neg[token]:\n",
    "                    if token not in wrongly_classified_dict:\n",
    "                        wrongly_classified_dict[token] = 1\n",
    "                    else:\n",
    "                        wrongly_classified_dict[token] += 1\n",
    "        elif real_label == \"negative\": # marked as positive\n",
    "            for token in tokens:\n",
    "                if token not in pos: continue\n",
    "                elif neg[token] < pos[token]:\n",
    "                    if token not in wrongly_classified_dict:\n",
    "                        wrongly_classified_dict[token] = 1\n",
    "                    else:\n",
    "                        wrongly_classified_dict[token] += 1\n",
    "    for word, prob in wrongly_classified_dict.items():\n",
    "        weight = 0\n",
    "        if pos[word] < neg[word]:\n",
    "            weight = pos[word] - neg[word]\n",
    "        elif neg[word] < pos[word]:\n",
    "            weight = neg[word] - pos[word]\n",
    "        multiplier = 1 - wrongly_classified_dict[word] / token_dict[word]\n",
    "        if multiplier == 0:\n",
    "            reweight_dict[word] = 0\n",
    "        else:\n",
    "            reweight_dict[word] = np.exp(weight) * multiplier\n",
    "    return reweight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perceptron Reweighting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(positive_prob_dict, negative_prob_dict, unseen_pos, unseen_neg, val_reviews, val_sentiments, test_reviews, test_sentiments, max_iter=10, learning_rate=0.02):\n",
    "    \"\"\"\n",
    "    need to handle unseen word here\n",
    "    has to be a method\n",
    "    \"\"\"\n",
    "    initial_weight = {}\n",
    "    for i in range(max_iter):\n",
    "        random_array = np.arange(len(val_sentiments))\n",
    "        np.random.shuffle(random_array)\n",
    "        correct = 0\n",
    "        for index in random_array:\n",
    "            word_list = val_reviews[index]\n",
    "            word_list = re.sub(pattern, \" \", word_list.lower()).split()\n",
    "            final_result = 0\n",
    "            for word in word_list:\n",
    "                weight = 1\n",
    "                pprob = unseen_pos\n",
    "                nprob = unseen_neg\n",
    "                if word not in initial_weight:\n",
    "                    initial_weight[word] = 1\n",
    "                if word in initial_weight:\n",
    "                    weight = initial_weight[word]\n",
    "                if word in positive_prob_dict:\n",
    "                    pprob = positive_prob_dict[word]\n",
    "                if word in negative_prob_dict:\n",
    "                    nprob = negative_prob_dict[word]\n",
    "                final_result += weight*pprob - weight*nprob\n",
    "            if (final_result > 0 and val_sentiments[index] == \"positive\") or (final_result < 0 and val_sentiments[index] == \"negative\"):\n",
    "                correct += 1\n",
    "                for word in word_list:\n",
    "                    initial_weight[word] -= learning_rate/len(val_sentiments)*initial_weight[word]\n",
    "            else:\n",
    "                for word in word_list:\n",
    "                    pprob = unseen_pos\n",
    "                    nprob = unseen_neg\n",
    "                    if word in positive_prob_dict:\n",
    "                        pprob = positive_prob_dict[word]\n",
    "                    if word in negative_prob_dict:\n",
    "                        nprob = negative_prob_dict[word]\n",
    "                    if val_sentiments[index] == \"positive\":\n",
    "                        initial_weight[word] += learning_rate*((pprob-nprob) - 1/len(val_sentiments)*initial_weight[word])\n",
    "                    else:\n",
    "                        initial_weight[word] += learning_rate*((nprob-pprob) - 1/len(val_sentiments)*initial_weight[word])\n",
    "        test_pred, test_acc = naive_inference(initial_weight, positive_prob_dict, negative_prob_dict, unseen_pos, unseen_neg, test_reviews, test_sentiments)\n",
    "        val_accuracy = correct/len(val_sentiments)\n",
    "        print(f\"finish training epoch {i}, the val accuracy is {val_accuracy}, the test accuracy is {test_acc}\")\n",
    "        \n",
    "    return initial_weight, val_accuracy, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.032443811652895 -15.049387153559886\n"
     ]
    }
   ],
   "source": [
    "neg, pos, mnb, transformed_val_reviews, transformed_test_reviews, vec= generate_log_prob(train_reviews, train_sentiments, test_reviews, val_reviews=val_reviews, alpha = 1)\n",
    "unseen_neg = mnb.feature_log_prob_[0].min()\n",
    "unseen_pos = mnb.feature_log_prob_[1].min()\n",
    "print(unseen_neg, unseen_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running - Baseline Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441\n",
      "0.8472\n",
      "val accuracy is 0.8441, test accuracy is 0.8472\n"
     ]
    }
   ],
   "source": [
    "val_pred_baseline, val_acc_baseline = naive_inference({}, pos, neg, unseen_pos, unseen_neg, val_reviews, val_sentiments)\n",
    "test_pred_baseline, test_acc_baseline = naive_inference({}, pos, neg, unseen_pos, unseen_neg, test_reviews, test_sentiments)\n",
    "print(f\"val accuracy is {val_acc_baseline}, test accuracy is {test_acc_baseline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running - Count Reweight Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running - Value Reweight Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9031\n",
      "0.841\n",
      "val accuracy is 0.9031, test accuracy is 0.841\n"
     ]
    }
   ],
   "source": [
    "wrong_labeled = []\n",
    "pattern = r'[^A-Za-z0-9]+'\n",
    "\n",
    "for i in range(len(val_reviews)):\n",
    "    start_index = 30000\n",
    "    if(val_pred_baseline[i] != val_sentiments[i]):\n",
    "        sentiment = val_sentiments[i]\n",
    "        review = str(imdb_data['review'][start_index + i])\n",
    "        review = re.sub(pattern, \" \", review.lower()).split()\n",
    "        wrong_labeled.append((sentiment, review))\n",
    "\n",
    "reweight_dict_value = calculate_reweight_dict(pos, neg, wrong_labeled)\n",
    "val_pred_value, val_acc_value = naive_inference(reweight_dict_value, pos, neg, unseen_pos, unseen_neg, val_reviews, val_sentiments)\n",
    "test_pred_value, test_acc_value = naive_inference(reweight_dict_value, pos, neg, unseen_pos, unseen_neg, test_reviews, test_sentiments)\n",
    "print(f\"val accuracy is {val_acc_value}, test accuracy is {test_acc_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running - Perceptron Reweight Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873\n",
      "finish training epoch 0, the val accuracy is 0.8623, the test accuracy is 0.873\n",
      "0.8821\n",
      "finish training epoch 1, the val accuracy is 0.8836, the test accuracy is 0.8821\n",
      "0.8825\n",
      "finish training epoch 2, the val accuracy is 0.894, the test accuracy is 0.8825\n",
      "0.8832\n",
      "finish training epoch 3, the val accuracy is 0.9055, the test accuracy is 0.8832\n",
      "0.8844\n",
      "finish training epoch 4, the val accuracy is 0.9099, the test accuracy is 0.8844\n",
      "0.884\n",
      "finish training epoch 5, the val accuracy is 0.9195, the test accuracy is 0.884\n",
      "0.8862\n",
      "finish training epoch 6, the val accuracy is 0.9238, the test accuracy is 0.8862\n",
      "0.8855\n",
      "finish training epoch 7, the val accuracy is 0.9316, the test accuracy is 0.8855\n",
      "0.8858\n",
      "finish training epoch 8, the val accuracy is 0.9346, the test accuracy is 0.8858\n",
      "0.8862\n",
      "finish training epoch 9, the val accuracy is 0.9414, the test accuracy is 0.8862\n"
     ]
    }
   ],
   "source": [
    "reweight, val_acc_perceptron, test_acc_perceptron = perceptron_update(pos, neg, unseen_pos, unseen_neg, val_reviews, val_sentiments, test_reviews, test_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Record Weight Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_printed_version = dict(sorted(reweight.items(), key=lambda item: item[1]))\n",
    "with open(\"weight_dict.txt\", \"w\") as f:\n",
    "    for k, v in weight_printed_version.items():\n",
    "        f.write(str(k))\n",
    "        f.write(\": \")\n",
    "        f.write(str(v))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('weight.pickle', 'wb') as handle:\n",
    "    pickle.dump(reweight, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "val_set = (val_acc_baseline, val_acc_value, val_acc_perceptron)\n",
    "test_set = (test_acc_baseline, test_acc_value, test_acc_perceptron)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60d1cc28a4b92593bd5dc5bc27ccc3190a35517554a34efe05fccaa5f4e07df9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
